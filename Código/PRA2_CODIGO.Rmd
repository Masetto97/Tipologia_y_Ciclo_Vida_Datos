---
title: '¿Cómo realizar la limpieza y análisis de datos?'
author: "Autores: Eduardo Mora González y Diego Sánchez De La Fuente"
date: "Enero 2023"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: 75.584-PEC-header.html
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

<style>
body {
text-align: justify}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Instalamos y cargamos las librerías necesarias.

```{r message= FALSE, warning=FALSE}
if (!require('readr')) install.packages('readr'); library('readr')
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')
if (!require('DataExplorer')) install.packages('DataExplorer'); library('DataExplorer')
if (!require('corrplot')) install.packages("corrplot"); library(corrplot)
if (!require('factoextra')) install.packages("factoextra"); library(factoextra)
if (!require('dplyr')) install.packages("dplyr"); library(dplyr)
if (!require('DescTools')) install.packages("DescTools"); library(DescTools)
if (!require('regclass')) install.packages("regclass"); library(regclass)
if(!require('randomForest')) install.packages('randomForest',repos='http://cran.us.r-project.org'); library(randomForest)
if(!require('iml')) install.packages('iml', repos='http://cran.us.r-project.org'); library(iml)
if(!require("tidyverse"))install.packages("DeskTools");library("tidyverse")
if(!require("rpart")) install.packages("rpart");library("rpart")
if(!require("rpart.plot")) install.packages("rpart.plot"); library("rpart.plot")
if(!require("caret"))install.packages("caret");library("caret")
if(!require('patchwork'))install.packages('patchwork',repos='http://cran.us.r-project.org');library(patchwork)
```

# Dataset

## Motivación

En Europa, el paro cardiaco es una de las primeras causas de mortalidad y en España fallecen en torno a 100 personas al día por este suceso [https://fundaciondelcorazon.com/prensa/notas-de-prensa/2900-solo-el-30-de-espanoles-sabe-realizar-la-reanimacion-cardio-pulmonar-rcp-.html], esto representa aproximadamente el 31% de las muertes a nivel mundial.

## Descripción del dataset

El conjunto de datos ha sido extraido de Kaggle: https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset, está compuesto de 12 variables y 918 registros. Que correlacionan una serie de caracteristicas recogidas de varios pacientes con la posibilidad de sufrir un ataque al corazón.

Explicación de cada variable:

- **Age**: Edad del paciente
- **Sex**: Sexo del paciente
- **ChestPainType**: Tipo de dolor torácico:
        Angina Típica
        Angina Atípica
        Dolor no debido a una angina
        Asintomático
- **RestingBP**: Presión arterial en reposo (en mm Hg)
- **Cholesterol**: Colesterol en sangre (mg/dL)
- **FastingBS**: Tiene Glucemia en ayunas > 120 mg/dl -> (1: True, 0: False) 
- **RestingECG**: Resultados electrocardiográficos en reposo
        Value 0: normal
        Value 1: Tiene anormalidad de la onda ST-T (inversiones de la onda T y/o elevación o depresión del ST > 0.05 mV)
        Value 2  Muestra hipertrofia ventricular izquierda probable o definitiva según los criterios de Estes
- **MaxHR**: Frecuencia cardíaca máxima alcanzada
- **ExerciseAngina**: Angina inducida por el ejercicio (1 = sí, 0 = no)
- **Oldpeak**: Descenso del segmento ST inducido por el ejercicio en relación con el reposo ('Segmento ST' se relaciona con las posiciones en el gráfico de Electro cardiograma). 
- **ST_Slope**: La pendiente del segmento ST de ejercicio máximo: 
	0: pendiente descendente 
	1: plano 
	2: pendiente ascendente
- **HeartDisease**: Variable Objetivo: 0= menos posibilidades de infarto 1= más posibilidades de infarto.

## Carga del fichero de datos

```{r message= FALSE, warning=FALSE}
datos <- read_csv("./fichero_original_datos.csv")
attach(datos)
```

## Tipos de datos

```{r}
# Cargamos en un vector los tipos de variable del datase
vector_tipos <- sapply(datos, function(x) class(x))
print(vector_tipos)
```

Ahora vamos a ver las estructura del juego de datos

```{r message= FALSE, warning=FALSE}
str(datos)
```

Vamos ahora a sacar estadísticas básicas
  
```{r message= FALSE, warning=FALSE}
summary(datos)
```

Observamos los primeros 5 registros:

```{r}
head(datos, 5L)
```

## Objetivo buscado

Se puede decir que el objetivo buscado es predecir la posibilidad de que una persona tenga un alto riesgo de ser diagnosticado como un paciente cardíaco a través de las diversas características. Para llegar a al objetivo se tiene pensado realizar diversos métodos de análisis para así relacionar las diversas características para obtener unos parámetros finales y así concluir la posibilidad de que una persona tenga o no una enfermedad cardiaca.

# Preprocesado, gestión de características y exploración de los datos.

## Valores nulos del conjunto de los datos

De tipo numérico

```{r message= FALSE, warning=FALSE}
colSums(is.na(datos))
```

De tipo cadena

```{r message= FALSE, warning=FALSE}
colSums(datos=="")
```

Como se puede comprobar, tenemos la “suerte” de no tener ningún valor nulo o vacío en los dos juegos de datos.

## Normalización del conjunto de los datos

### EDAD (Age)

```{r message= FALSE, warning=FALSE}
#Histograma de la característica edad del primer conjunto de datos 
h1 <- hist(datos$Age, xlab="Edad", col="ivory",
           ylab="Cantidad", main="EDAD ", ylim = c(0, 225), xlim = c(20,80))
text(h1$mids,h1$counts,labels=h1$counts, adj=c(0.5, -0.5))
```

Como se puede observar, la franja de entre los 50 y 60 años son donde más datos existen, mientras que los extremos donde menos datos.

### SEXO (Sex)
  
Normalizamos para tenerlo de tipo numérico todas la variables
  
```{r message= FALSE, warning=FALSE}
#Cambiamos las letras por los números
datos$Sex [datos$Sex == "M"] <- 1
datos$Sex [datos$Sex == "F"] <- 0

#Pasamos de carácter a numérico
datos$Sex <- as.numeric(datos$Sex)

```

Una vez normalizada la característica , analizamos el conjunto de los datos contemplados en esta.

```{r message= FALSE, warning=FALSE}
h1 <- hist(datos$Sex, xlab="Sexo", col=c("ivory", "lightcyan"),
           ylab="Cantidad", main="SEXO", breaks = 2, ylim = c(0, 750), axes = FALSE)
text(h1$mids,h1$counts,labels=h1$counts, adj=c(0.5, -0.5))
axis(1, at =c(0.25, 0.75), cex.axis=1, labels = c("Mujeres","Hombres" ))
axis(2)
```

### TIPO DE DOLOR TORÁCICO (ChestPainType)

Nos damos cuenta de que el conjunto de datos viene identificado por 4 variables categóricas (TA: angina típica, ATA: angina atípica, NAP: dolor no anginal, ASY: asintomático). Normalizamos para tenerlo de tipo numérico todas la variables:

```{r message= FALSE, warning=FALSE}
#Cambiamos las letras por los números
datos$ChestPainType [datos$ChestPainType == "TA"]  <- 0
datos$ChestPainType [datos$ChestPainType == "ATA"] <- 1
datos$ChestPainType [datos$ChestPainType == "NAP"] <- 2
datos$ChestPainType [datos$ChestPainType == "ASY"] <- 3

#Pasamos de carácter a numérico
datos$ChestPainType <- as.numeric(datos$ChestPainType)
``` 

Una vez normalizada la característica , analizamos el conjunto de los datos contemplados en esta.

```{r message= FALSE, warning=FALSE}
h1 <- hist(datos$ChestPainType, xlab="Tipo de dolor torácico",
           col= c("ivory", "lightcyan", "ORANGE", "PINK"), 
           ylab="Cantidad", main="TIPO DOLOR TORÁCICO", 
           ylim = c(0, 550),axes = FALSE, 
           breaks=seq(min(datos$ChestPainType)-0.5,
                      max(datos$ChestPainType)+0.5, by=1) )
text(h1$mids,h1$counts,labels=h1$counts, adj=c(0.5, -0.5))
axis(1, at =c(0,1,2,3), cex.axis=1,
     labels = c("Angina típica", "Angina atípica","Dolor no anginal", "Asintomático" ))
axis(2)
```

como se puede comprobar, tenemos mas casos de de asintomaticos que del resto.

### PRESIÓN ARTERIAL EN REPOSO (RestingBP)
  
Como se muestran en las estadísticas esta característica es de tipo numérico y en el conjunto de datos va desde 0 hasta 200. Como se puede apreciar, tener una presión arterial de 0 es estar considerado muerto, por lo que considero que el valor 0 es un valor nulo.

Lo primero que se va a hacer es obtener el número de casos que la presión arterial es 0, y se consideraran las diversas formas de tratar estos datos:

```{r message= FALSE, warning=FALSE}
#Veces que aparece el valor cero en la presion arterial
length(datos$RestingBP[datos$RestingBP == 0])
```

Como solo aparece una vez, se le asignará un valor por defecto. El valor por defecto será el más común.

```{r message= FALSE, warning=FALSE}
#Función para calcular el valor más común
common_value <- function(x) {
uniqx <- unique(na.omit(x))
uniqx[which.max(tabulate(match(x, uniqx)))]
}

#Calculamos el valor más comun
BP_comun <- common_value(datos$RestingBP)

#Asignamos el valor
datos$RestingBP[datos$RestingBP == 0] <- BP_comun

#vemos las estaditicas del dato
summary(datos$RestingBP)
```

Ahora ya tenemos los valores entre 80 y 200 que son un rango normal para estos valores.

```{r message= FALSE, warning=FALSE}
#Histograma de la característica Presión Arterial del primer conjunto de datos 
h1 <- hist(datos$RestingBP, xlab="Presión Arterial", col="ivory", 
           ylab="Cantidad", main="PRESIÓN ARTERIAL EN REPOSO",
           ylim = c(0, 225), xlim = c(80,200))
text(h1$mids,h1$counts,labels=h1$counts, adj=c(0.5, -0.5))
```

### COLESTEROL (Cholesterol)
  
La siguiente característica es de tipo numérico. Al igual que en la presión arterial en reposo, que tenemos valores 0 que debemos analizar. Lo primero que se va a hacer es obtener el numero de casos que el colesterol es 0, y se consideraran las diversas formas de tratar estos datos.

```{r message= FALSE, warning=FALSE}
#Veces que aparece el valor cero en la presion arterial
length(datos$RestingBP[datos$Cholesterol == 0])
```

Esta vez tenemos 172 casos en lo que ocurre esto (equivale a un 18% de los casos totales). Antes de ver que valor se le asignan, se va a graficar los datos para ver de manera grafica que opción tomar: el valor medio o el más común.

```{r message= FALSE, warning=FALSE}
h1 <- hist(datos$Cholesterol, xlab="Colesterol", col="ivory",
           ylab="Cantidad", main="COLESTEROL SIN TRATAR NULOS", ylim = c(0,300),
           xlim = c(0, 700))
text(h1$mids,h1$counts,labels=h1$counts, adj=c(0.5, -0.5))
```

Tras analizar la gráfica y para no perder estos datos, se le asignaran un valor por defecto, que será la media de los datos. Esta decisión se ha tomado ya que poner el más común, nos crearía un conjunto de datos muy distintos entre unas medidas y otras, mientras que poner la media sería un valor que tenga en cuenta el grueso de todos los datos.

```{r message= FALSE, warning=FALSE}
#Calculamos el valor más comun
colesterol_media <- mean(datos$Cholesterol)

#Asignamos el valor truncado para evitar decimales
datos$Cholesterol[datos$Cholesterol == 0] <- trunc(colesterol_media)

#vemos las estaditicas del dato
summary(datos$RestingBP)
```

Ahora ya tenemos los valores entre 80 y 200 que son un rango normal para estos valores.

```{r message= FALSE, warning=FALSE}
h1 <- hist(datos$Cholesterol, xlab="Colesterol", col="ivory",
           ylab="Cantidad", main="COLESTEROL", ylim = c(0,330), xlim = c(0, 700))
text(h1$mids,h1$counts,labels=h1$counts, adj=c(0.5, -0.5))
```

### NIVEL DE AZÚCAR EN SANGRE EN AYUNAS (FastingBS)
  
Como se puede comprobar el conjunto de los datos puedes ser 1 o 0, es decir verdadero o falso si se cumple la siguiente condición: si nivel de azúcar en sangre en ayunas> 120 mg / dl.

En esta característica no tenemos valores nulos, así que vamos a ver la distribución de las dos opciones:

```{r message= FALSE, warning=FALSE}
h1 <- hist(datos$FastingBS, xlab="¿Azúcar en sangre en ayunas> 120 mg / dl?",
           col=c("ivory", "lightcyan"), ylab="Cantidad",
           main="NIVEL DE AZÚCAR", breaks = 2, ylim = c(0, 750), axes = FALSE)
text(h1$mids,h1$counts,labels=h1$counts, adj=c(0.5, -0.5))
axis(1, at =c(0.25, 0.75), cex.axis=1, labels = c("NO","SI" ))
axis(2)
```

Como se puede comprobar que hay mas casos que NO se cumple esa condición de que SÍ.

### ECG EN REPOSO (RestingECG)

Nos damos cuenta de que el conjunto de datos viene identificado por 3 variables categóricas:
 + Normal: Normal, 
 + ST: con anomalía de la onda ST-T
 + LVH: que muestra una hipertrofia ventricular izquierda probable o definitiva según los criterios de Estes.
Normalizamos para tenerlo de tipo numérico todas la variables:

```{r message= FALSE, warning=FALSE}
#Cambiamos las letras por los números
datos$RestingECG [datos$RestingECG == "Normal"]  <- 0
datos$RestingECG [datos$RestingECG == "ST"] <- 1
datos$RestingECG [datos$RestingECG == "LVH"] <- 2

#Pasamos de carácter a numérico
datos$RestingECG <- as.numeric(datos$RestingECG)
```

Una vez normalizada la característica , analizamos el conjunto de los datos contemplados en esta.

```{r message= FALSE, warning=FALSE}
h1 <- hist(datos$RestingECG, xlab="ECG en reposo",
           col= c("ivory", "lightcyan", "ORANGE"),
           ylab="Cantidad", main="ECG EN REPOSO",
           ylim = c(0, 600), axes = FALSE,
           breaks=seq(min(datos$RestingECG)-0.5,
                      max(datos$RestingECG)+0.5, by=1) )
text(h1$mids,h1$counts,labels=h1$counts, adj=c(0.5, -0.5))
axis(1, at =c(0.25, 1, 1.75 ), cex.axis=1, labels = c("Normal","ST", "LVH"))
axis(2)
```

### FRECUENCIA CARDÍACA MÁXIMA (MaxHR)

Dicha característica es de carácter numérica y en el conjunto de datos contempla valores desde el 60 al 202 

```{r message= FALSE, warning=FALSE}
h1 <- hist(datos$MaxHR, xlab="Frecuencia Cardíaca Máxima",
           col="ivory", ylab="Cantidad", main="FRECUENCIA CARDÍACA MÁXIMA",
           ylim = c(0,140), axes = FALSE)
text(h1$mids,h1$counts,labels=h1$counts, adj=c(0.5, -0.5))
axis(1, at =c(60, 70, 80,90,100,110,120,130,140,150,160,170,180,190,200,210), cex.axis=1)
axis(2)
```

Se puede comprobar que los extremos en el conjunto de datos tienen menos valores, y que el grueso de las muestras se encuentran entre los valores centrales (desde 100 a 180).

### ANGINA INDUCIDA POR EJERCICIO (ExerciseAngina)
  
En el  conjunto de datos tiene los valores Y: Sí, N: No. Al igual que se ha hecho con otras características, se normalizará el conjunto.

```{r message= FALSE, warning=FALSE}
#Cambiamos las letras por los números
datos$ExerciseAngina [datos$ExerciseAngina == "N"]  <- 0
datos$ExerciseAngina [datos$ExerciseAngina == "Y"]  <- 1

#Pasamos de carácter a numérico
datos$ExerciseAngina <- as.numeric(datos$ExerciseAngina)
```

Una vez normalizada la característica , analizamos el conjunto de los datos contemplados en esta.

```{r message= FALSE, warning=FALSE}
h1 <- hist(datos$ExerciseAngina, xlab="¿Angina inducida por ejercicio?",
           col=c("ivory", "lightcyan"), ylab="Cantidad", main="ANGINA INDUCIDA",
           breaks = 2, ylim = c(0, 600), axes = FALSE)
text(h1$mids,h1$counts,labels=h1$counts, adj=c(0.5, -0.5))
axis(1, at =c(0.25, 0.75), cex.axis=1, labels = c("NO","SI" ))
axis(2)
```

Como se puede apreciar, hay mas casos en que NO se ha producido una angina inducida por el ejercicio de que Si se haya producido.

### OLDPEAK
  
Esta característica de tipo numérica puede abarcar valores negativos hasta  hasta un máximo de un valor igual a 6,2.

```{r message= FALSE, warning=FALSE}
h1 <- hist(datos$Oldpeak, xlab="Oldpeak", col="ivory", ylab="Cantidad", main="OLDPEAK", ylim = c(0,400), xlim = c(-4, 8))
text(h1$mids,h1$counts,labels=h1$counts, adj=c(0.5, -0.5))
```

Se puede comprobar que el grueso de las muestras se encuentra entre los valores centrales teniendo una distribución normal

### PENDIENTE DEL SEGMENTO ST (ST_Slope)

Como ocurría en otras características anteriores el conjunto tiene los valores para esta caracteristica de la siguiente forma:
  + Up: uploping
  + Flat: flat
  + Down: downsloping
Y como se ha realizado antes, se normalizará para solo tener datos numericos.

```{r message= FALSE, warning=FALSE}
#Cambiamos las letras por los números
datos$ST_Slope [datos$ST_Slope == "Up"]   <- 0
datos$ST_Slope [datos$ST_Slope == "Flat"] <- 1
datos$ST_Slope [datos$ST_Slope == "Down"] <- 2

#Pasamos de carácter a numérico
datos$ST_Slope <- as.numeric(datos$ST_Slope)
```

Una vez normalizada la característica , analizamos el conjunto de los datos contemplados en esta.

```{r message= FALSE, warning=FALSE}
h1 <- hist(datos$ST_Slope, xlab="Pendiente del segmento ST",
           col= c("ivory", "lightcyan", "ORANGE"), ylab="Cantidad",
           main="PENDIENTE DEL SEGMENTO ST", ylim = c(0, 500),
           axes = FALSE,breaks=seq(min(datos$ST_Slope)-0.5, max(datos$ST_Slope)+0.5, by=1) )
text(h1$mids,h1$counts,labels=h1$counts, adj=c(0.5, -0.5))
axis(1, at =c(0.25,1,1.75), cex.axis=1, labels = c("Ascendente","Plano", "Descendente"))
axis(2)
```

El caso más común es que la pendiente sea plana, teniendo menos casos en los casos descendentes.

### ¿ENFERMEDAD CARDIACA? (HeartDisease)

En el conjunto de datos tienen normalizada la salida usando el valor 1: enfermedad cardíaca, y el valor 0: Normal.

```{r message= FALSE, warning=FALSE}
h1 <- hist(datos$HeartDisease, xlab="¿Enfermedad Cardiaca?",
           col=c("ivory", "lightcyan"),
           ylab="Cantidad", main="¿ENFERMEDAD CARDIACA?",
           breaks = 2, ylim = c(0, 600), axes = FALSE)
text(h1$mids,h1$counts,labels=h1$counts, adj=c(0.5, -0.5))
axis(1, at =c(0.25, 0.75), cex.axis=1, labels = c("NO","SI" ))
axis(2)
```

Como se puede observar hay mas casos en que SI hay enfermedad cardiaca que caso en los que NO hay.

## Construcción de conjunto de datos final

Renombramos las columnas para que tenga uno mas significativo y creamos el conjunto final de datos.

```{r message= FALSE, warning=FALSE}

datos_final <- datos

colnames(datos_final)[1]<-  "EDAD"
colnames(datos_final)[2]<-  "SEXO"
colnames(datos_final)[3]<-  "TIPO_DOLOR_TORAX"
colnames(datos_final)[4]<-  "PRESION_ARTERIAL"
colnames(datos_final)[5]<-  "COLESTEROL"
colnames(datos_final)[6]<-  "NIVEL_DE_AZUCAR"
colnames(datos_final)[7]<-  "ECG_EN_REPOSO"
colnames(datos_final)[8]<-  "FREC_CARDIACA_MAX"
colnames(datos_final)[9]<-  "ANGINA_x_EJERCICIO"
colnames(datos_final)[10]<- "OLDPEAK"
colnames(datos_final)[11]<- "PENDIENTE_ST"
colnames(datos_final)[12]<- "E_CARDIACA"

```

Por ultimo se va a mirar a través de los diagramas de cajas el rango de las características enfrentado a si un paciente tiene una enfermedad cardiaca o no.

```{r message= FALSE, warning=FALSE}
#Diagrama de caja de todas las características enfrentadas a si un paciente tiene enfermedad cardiaca
plot_boxplot(datos_final, by = "E_CARDIACA")
```

## Eliminamos outliers

```{r}
datos_bp.colesterol <- boxplot(datos_final$COLESTEROL)
datos_bp.colesterol.out <- datos_bp.colesterol$out
print("Eliminamos Outliers de la variable COLESTEROL con valores: ")
datos_bp.colesterol.out
datos_final <- datos_final %>% filter(!(COLESTEROL %in% datos_bp.colesterol.out))
dev.off()

datos_frec.cardiaca.max <- boxplot(datos_final$FREC_CARDIACA_MAX)
datos_frec.cardiaca.max.out <- datos_frec.cardiaca.max$out
print("Eliminamos Outliers de la variable FREC CARDIACA MAX con valores: ")
datos_frec.cardiaca.max.out
datos_final <- datos_final %>% filter(!(FREC_CARDIACA_MAX %in% datos_frec.cardiaca.max.out))
dev.off()

datos_oldpeak <- boxplot(datos_final$OLDPEAK)
datos_oldpeak.out <- datos_oldpeak$out
print("Eliminamos Outliers de la variable OLDPEAK con valores: ")
datos_oldpeak.out
datos_final <- datos_final %>% filter(!(OLDPEAK %in% datos_oldpeak.out))
dev.off()


datos_bp.presion_arterial <- boxplot(datos_final$PRESION_ARTERIAL)
datos_bp.presion_arterial.out <- datos_bp.presion_arterial$out
print("Eliminamos Outliers de la variable PRESIÓN ARTERIAL ST con valores: ")
datos_bp.presion_arterial.out
datos_final <- datos_final %>% filter(!(PRESION_ARTERIAL %in% datos_bp.presion_arterial.out))
dev.off()


datos_bp.tipo_dolor_torax <- boxplot(datos_final$TIPO_DOLOR_TORAX)
datos_bp.tipo_dolor_torax.out <- datos_bp.tipo_dolor_torax$out
print("Eliminamos Outliers de la variable TIPO DOLOR TORAX con valores: ")
datos_bp.tipo_dolor_torax.out
datos_final <- datos_final %>% filter(!(TIPO_DOLOR_TORAX %in% datos_bp.tipo_dolor_torax.out))
dev.off()
```

```{r message= FALSE, warning=FALSE}
#Diagrama de caja de todas las características enfrentadas a si un paciente tiene enfermedad cardiaca
plot_boxplot(datos_final, by = "E_CARDIACA")
```

## Correlaciones

```{r message= FALSE, warning=FALSE}
#Calculamos las correlaciones
cor_datos <- cor(datos_final)
cor_datos
```

```{r message= FALSE, warning=FALSE}
#Representación de las correlaciones
corrplot(cor_datos, method = "pie", type="upper")
```

## Análisis de componentes principales (PCA)

Ahora se va a realizar un análisis de componentes sobre el conjunto de datos final. Lo primero que vamos a calcular es la varianza de todas las caracteristicas

```{r message= FALSE, warning=FALSE}
#Cálculo de la varianza de los componentes.
var <- apply(datos_final, 2, var)
var
```

Como se puede observar de una manera bastante clara, el colesterol es la característica que mas varia de un individuo a otro.

Lo siguiente es centrar y escalar las características, para que así las variables pierdan esa variabilidad. Una vez calculada la matriz se la asigno al pca

```{r message= FALSE, warning=FALSE}
#Calculo de la descomposición de los componentes
pca <- prcomp(datos_final, scale = TRUE, center = TRUE)
pca
```

Se puede ver que la primera componente tiene la mayor desviación estándar de todos los componentes. Para verlo de una manera mas clara, se va a representar de una manera grafica la salida anterior

```{r message= FALSE, warning=FALSE}
#Representación PCA´s anteriores
fviz_eig(pca)
```

Como se ha visto antes, tanto de una manera numérica como gráfica, el PC1 es el que mejor de todos con una diferencia notable. Si usamos la técnica del codo, deberíamos coger solamente las dos primeras componentes.

Para confirmar la interpretación, no estaría de más obtener las estadísticas de todas las componentes

```{r message= FALSE, warning=FALSE}
#Estadísticas de las componentes
summary(pca)
```

Viendo las estadísticas vemos que con las dos primeras componentes solamente podríamos explicar un 39,75% de los datos.Como no queremos perder información en el modelo, nos tendríamos que quedar con todas las componentes. Para verlo de una manera visual, se va a representar la PCA de una manera gráfica.

```{r message= FALSE, warning=FALSE}
#Representación de variables sobre componentes principales
fviz_pca_var(pca, repel = TRUE, scale = 0)
```

```{r message= FALSE, warning=FALSE}
#Representación de observaciones sobre componentes principales
fviz_pca_ind(pca, col.ind = "cos2", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE)
```

```{r message= FALSE, warning=FALSE}
#Representa la contribución de filas/columnas de los resultados de un pca
fviz_contrib(pca,choice = "var") 
```

Una vez que hemos representada las variables y los individuos, se va a fusionar estas dos gráficas

```{r message= FALSE, warning=FALSE}
#Representación de variables y los individuos en la misma gráfica
fviz_pca_biplot(pca, repel = TRUE, col.var = "#2E9FDF", col.ind = "#696969")
```

Aunque la opción de repelerse esta activada al ser bastantes casos no se puede ver una manera correcta, así que se a mostrar solamente los 10, 50 y 100 casos más influyentes

```{r message= FALSE, warning=FALSE}
#Representación de variables y los 10 individuos más influyentes en la misma gráfica
fviz_pca_biplot(pca, repel = TRUE, col.var = "#2E9FDF",
                col.ind = "#696969", select.ind = list(contrib = 10))

#Representación de variables y los 50 individuos más influyentes en la misma gráfica
fviz_pca_biplot(pca, repel = TRUE, col.var = "#2E9FDF",
                col.ind = "#696969", select.ind = list(contrib = 50))

#Representación de variables y los 100 individuos más influyentes en la misma gráfica
fviz_pca_biplot(pca, repel = TRUE, col.var = "#2E9FDF",
                col.ind = "#696969", select.ind = list(contrib = 100))
```

Al mostrar solamente los casos mas influyentes, se puede ver con mas claridad las relaciones entre los individuos y las características. Podemos concluir de este análisis de componentes, que no se puede quitar ninguna característica ya que se perdería información.

## Comprobación de la normalidad y la homogeneidad de la varianza variables numericas

Para la comprobación de que los valores que toman nuestra variables cuantativa provienen de una distirbución normal vamos a utilizar la prueba de normalidad de Anderson-Darling.

Podemos comprobar que para cada prueba se obtiene un p-valor superior al nivel de significancia estadistica prefijado en alpha = 0,05. Si esto se cumple, entonces se considera que variable en cuestion sigue la distribución normal.

```{r message= FALSE, warning=FALSE}
if (!require('nortest')) install.packages('nortest'); library('nortest')
alpha = 0.05
col.names = colnames(datos_final)
ind = 1

# Comprobanos unicamente lS variables que inicialmente eran de tipo numericas

for (i in colnames(datos_final)) {
  if (ind == 1) cat("Variables que no siguen una distribución normal:\n")
  if(vector_tipos[ind] == "numeric")
  {
    p_val = ad.test(unlist(datos_final[i]))$p.value
    if (p_val < alpha) {
      cat(i)
      # Format output
        if (ind < ncol(datos) - 1) cat(", ")
        if (ind %% 3 == 0) cat("\n")
      }
  }
  ind = ind + 1
  }
```

Podemos realizar un Q-Q plot para comprobar si las variables obtenidas en el anterior punto no siguen una distribución normal.

```{r message= FALSE, warning=FALSE}
variables <- c("EDAD", "PRESION_ARTERIAL", "COLESTEROL",
               "FREC_CARDIACA_MAX", "OLDPEAK")


for(i in(variables))
{
  qqnorm(unlist(datos_final[i]),  main = paste0("Q-Q para la variable: ", i));qqline(unlist(datos_final[i]), col = 2)
}

```

Vemos que tanto la distribución de los valores de las caracteristicas de EDAD y de la Frecuencia Cardica máxima se acercan mucho a la normalidad, por otro lado la distribución de los valores de la caracteristica Presión Arterial, Colesterol y Old distan de la normal.
 
# Exportación de los datos

Una vez que hemos acometido sobre el conjunto de datos inicial los procedimientos de integración, validación y limpieza anteriores, procedemos a guardar estos en un nuevo fichero denominado heart_dissease_data_clean.csv:

```{r message= FALSE, warning=FALSE}
# Exportación de los datos limpios en .csv
write.csv(datos_final, "./heart_dissease_data_clean.csv")
```

# Análisis de los datos

## ¿Cuáles son los factores o parámetros que más influyen a la hora de tener una enfermedad cardiaca? (Correlaciones y Regresión logística)

### Test de Spearman

```{r message= FALSE, warning=FALSE}
corr_matrix <- matrix(nc=2, nr=0)
colnames(corr_matrix) <- c("estimate", "p-value")

# Calculamos el coficiente de correlacion para cada variable cuantitativa
# con respecto al campo E. CARDICA

for(i in 1:(ncol(datos_final) -1 ))
{
  if(vector_tipos[i] == "numeric")
  {
    spearman_test = cor.test(unlist(datos_final[,i]),
                              unlist(datos_final[,length(datos_final)]),
                              method = "spearman")
    corr_coef <- spearman_test$estimate
    p_val <- spearman_test$p.value
    
    # Aañade a la matriz
    pair <- matrix(ncol = 2, nrow = 1)
    pair[1][1] = corr_coef
    pair[2][1] = p_val
    corr_matrix <- rbind(corr_matrix, pair)
    rownames(corr_matrix)[nrow(corr_matrix)] <- colnames(datos_final)[i]
  }
  
}

print(corr_matrix)

```

Podemos identificar cual es la variable más correlacionada con la variable Enfermedad Cardiaca, viendo cuales de los valores de la columan estimate se acercan más al valor +1 o -1, en este caso los más cercanos y por lo tanto los que más correlacionados están con la varibale objetivo son: OLDPEAK y FREC CARDÍACA MAX.

Por otro lado en la columna p-value, tenemos el indicador del peso estadistico de diga variable, en este caso las variables que tienen peso estadistico más alto son: COLESTEROL y PRESION ARTERIAL.

### Regresión logística

####  Generación de los conjuntos de entrenamiento y de test

```{r message= FALSE, warning=FALSE}
set.seed(123)
ind <- sample(seq_len(nrow(datos_final)), size = round(.8 * dim(datos_final)[1]))
training <- datos_final[ind, ]
testing <- datos_final[-ind, ]
prop.table(table(datos_final$E_CARDIACA))
```

```{r message= FALSE, warning=FALSE}
prop.table(table(training$E_CARDIACA))
```

```{r message= FALSE, warning=FALSE}
prop.table(table(testing$E_CARDIACA))
```

####  Estimación del modelo con el conjunto de entrenamiento e interpretación

```{r message= FALSE, warning=FALSE}
#Estimación del modelo
mod1<- glm(E_CARDIACA~.,data=training[,-1], family=binomial)
summary(mod1)
```

Existe colinealidad en todas la variables menos en: FREC_CARDIACA_MAX, ANGINA_x_EJERCICIO, OLDPEAK y PENDIENTE_ST

```{r message= FALSE, warning=FALSE}
training2 = training %>%
select(-SEXO,-TIPO_DOLOR_TORAX, -PRESION_ARTERIAL, -COLESTEROL, -NIVEL_DE_AZUCAR, -ECG_EN_REPOSO)
ModlgF<- glm(E_CARDIACA~.,data=training2, family=binomial)
summary(ModlgF)
```
 
Se observa que todas las variables explicativas son significativas con un nivel de significación del 5%
 
####  Predicciones con con casos del dataframe

```{r message= FALSE, warning=FALSE}
pred_1 <-predict (ModlgF, datos_final[1,], type = "response")
cat("La probabilidad de que el primer usuario tenga una enfermedad cardiaca es del: ", pred_1*100)
```

```{r message= FALSE, warning=FALSE}
pred_14 <-predict (ModlgF, datos_final[14,], type = "response")
cat("La probabilidad de que el usuario 14 tenga una enfermedad cardiaca es del: ", pred_14*100)
```

Nos damos cuenta de que la probabilidad obtenida es muy acertada a si esos usuarios han tenido o no enfermedad cardiaca.

## ¿Influye el sexo en tener una enfermedad cardiaca? (Contraste de hipótesis)

Vamos a realizar una prueba estadistica para establecer un contraste de hipótesis sobre dos muestras (una con presión arterial alta y otra con presión arterial normal) y ver cual de ellas tiene mayor probabilidades de sufrir enfermedad cardiaca.


### Hipótesis nula y la alternativa

H0 : Enf.Cardiaca_Mujer = Enf.Cardiaca_Hombre

H1 : Enf.Cardiaca_Mujer != Enf.Cardiaca_Hombre

### Preparación datos

```{r message= FALSE, warning=FALSE}
hombres <- datos_final[datos_final$SEXO==1,]
mujeres <- datos_final[datos_final$SEXO==0,]

var.test( as.numeric(hombres$E_CARDIACA),  as.numeric(mujeres$E_CARDIACA) )
```

El resultado del test muestra diferencias significativas entre varianzas (p=0.04968). Por tanto, aplicaremos un test de dos muestras independientes sobre la media con varianzas desconocidas diferentes.

### Cálculo

```{r message= FALSE, warning=FALSE}
t.test( as.numeric(datos_final$SEXO), as.numeric(datos_final$E_CARDIACA), alternative="greater", conf.level=0.95)
```

###  Interpretación del test

Existen diferencias significativas en tener enfermedad cardiaca entre los hombres y la mujeres (p=2.2e-16) por lo que se encuentra fuera de la zona de aceptación de la hipótesis nula, es decir, se acepta la hipótesis alternativa.


## Modelo Arbol de Decision

Podemos elaborar un arbol de decisión, para ver que variables tienen más influencia en la enfermedad cardiaca y establecer las reglas que definen dicha variable.

### Test estadísticos de significancia

Antes de proceder a la clasificación de los parámetros de pacientes con más probabilidades de sufrir enfermedad cardiaca, deberemos de hacer una selección previa de las caracteristicas a utilizar en nuestro modelo.

Para ello nos vamos a ayudar de una matriz de correlación con el objetivo de confirmar las conclusiones en cuanto a correlación de variables obtenidas en el apartado anterior.

Para aplicar los modelos de arbol de decision debemos de discretizar las variables COLESTEROL y FREC CARDIACA MAXIMA.

```{r message= FALSE, warning=FALSE}
# Backup dataset inicial:
datos_final_orig <- datos_final

datos_final <- datos_final %>% mutate(COLESTEROL = case_when(
  COLESTEROL < 100 ~ 0,
  (COLESTEROL >= 100 & COLESTEROL < 200) ~ 1,
  (COLESTEROL >= 200 & COLESTEROL < 300) ~ 2,
  (COLESTEROL >= 300 & COLESTEROL < 400) ~ 3,
  (COLESTEROL >= 400 & COLESTEROL < 500) ~ 4,
  COLESTEROL >= 600 ~ 5,
  ))


datos_final <- datos_final %>% mutate(FREC_CARDIACA_MAX = case_when(
  FREC_CARDIACA_MAX < 50 ~ 0,
  (FREC_CARDIACA_MAX >= 50 & FREC_CARDIACA_MAX < 80) ~ 1,
  (FREC_CARDIACA_MAX >= 80 & FREC_CARDIACA_MAX < 110) ~ 2,
  (FREC_CARDIACA_MAX >= 110 & FREC_CARDIACA_MAX < 140) ~ 3,
  (FREC_CARDIACA_MAX >= 140 & FREC_CARDIACA_MAX < 170) ~ 4,
  (FREC_CARDIACA_MAX >= 170 & FREC_CARDIACA_MAX < 200) ~ 5,
  FREC_CARDIACA_MAX >= 200 ~ 6,
  ))


# Convertimos todas las variables a tipo factor
datos_final[] <- lapply(datos_final, factor)

# Analizamos las correlaciones de todos las caracteristicas de tipo categoricas con "E. CARDIACA"
# Lo añadimos a una tabla

datos_corr.Phi <- list()
datos_corr.CramerV <- list()
datos_corr.nombre <- list()

vector_tipos[8] <- "character"
vector_tipos[5] <- "character"

ind <- 1
for (i in colnames(datos_final))
{
  
  if(i != "E_CARDIACA")
  {
    tabla_cruzada <- table(as.numeric(unlist(datos_final[i])), datos_final$E_CARDIACA)
    datos_corr.CramerV <- append(datos_corr.CramerV, CramerV(tabla_cruzada))
    datos_corr.Phi <- append(datos_corr.Phi, Phi(tabla_cruzada))
    datos_corr.nombre <- append(datos_corr.nombre, i)
  }
  
  if (vector_tipos[ind] != 'numeric')
  {
    # Solo pintamos las variables categoricas ya que con las de tipo numerico no se aprecian los valores
    plot(tabla_cruzada, col = c("black","#008000"), main = paste0(i, " vs. E. CARDIACA"))
  }
  
  ind <- ind + 1
  
}

n_list <- list(nombre=as.character(datos_corr.nombre),
               CamerV=as.numeric(datos_corr.CramerV),
               Phi=as.numeric(datos_corr.Phi))

df_CramerV <- (as.data.frame(do.call(cbind, n_list)))
print(df_CramerV[order(df_CramerV$Phi, decreasing = TRUE),])

```

Obtenemos las siguientes conclusiones del dataset:

  + En cuanto al Sexo, las Mujeres tienen menos probabilidad de sufrir una enfermedad cardiaca.

  + En cuanto al tipo de dolor de Torax, los pacientes que sufren de dolor tipo Asintomáticos son los que pese a lo que se pdoría pensar tienen más probabilidades de sufrir enfermedad cardiaca.

  + COLESTEROL: Vemos que cuando el colesterol está en valores comprendidos entre 100-200 y 300-400 hay más posibilidades de enfermedad cardiaca que en valores entre 200-300, probablemente porque existan medicación para pacientes con dichas enfermedades que se enfocan en reducir el colesterol

  + FREC CARDIACA MAXIMA hay correlación negativa con la enfermedad cardiaca es decir contra menor frecuencia más posibilidades de sufrir enfermedad cardiaca.

  + En cuanto al ECG en Reposo, tenemos que hay más probabilidades de Enfermedad Cardiaca cuando esta variable toma el valor 1 (ST -> Tiene anormalidad de la onda ST-T (inversiones de la onda T y/o elevación o depresión del ST > 0.05 mV))

  + Angina por Ejercicio -> Cuando esta toma el valor 1 (es decir hay angina inducida por ejercicio) hay más probabilidades de Enfermedad Cardiaca.

  + En cuanto a la variable Pendiente ST, si esta indica valor 1 y 2, hay una alta probabilidad de sufrir enfermedad cardíaca. 

### Prueba de la C de Crámer

Valores de la V de Cramér ([https://en.wikipedia.org/wiki/Cramér%27s_V](https://en.wikipedia.org/wiki/Cramér%27s_V){.uri}) y Phi (<https://en.wikipedia.org/wiki/Phi_coefficient>) entre 0.1 y 0.3 nos indican que la asociación estadística es baja, y entre 0.3 y 0.5 se puede considerar una asociación media. Finalmente, si los valores fueran superiores a 0.5 la asociación estadística entre las variables sería alta.

Podemos observar dentro del dataframe: df_cramerV que las variables PENDIENTES ST, COLESTEROL, TIPO DOLOR TORAX, FREC CARDIACA MAX y OLDPEAK tienen correlación alta con E. CARDIACA.

Usaremos dichas variables para la obtención del Arbol de decisión, se podria utilizar un número mayor de variables, pero podría hacerse mucho complejo (con muchas reglas de decisión)

```{r message= FALSE, warning=FALSE}
# caracteristicas con significancia estadistica:
nombres_columnas <- df_CramerV$nombre[df_CramerV$Phi > 0.5]
nombres_columnas
```

### Aplicación del modelo Decision Tree (Arbol de decisión)

Aplicamos el modelo Decision Tree sobre las 3 caracteristicas que hemos obtenido en el test de significacia estadistica de Cramer V.

```{r message= FALSE, warning=FALSE}


# Reducimos el datset
for(i in colnames(datos_final))
{
  if(!i %in% nombres_columnas)
  {
    if (!i == "E_CARDIACA")
    {
      datos_final$i <- NULL
    }
  }
}

```

Separamos conjunto de test y de entrenamiento con una proporción 33% Test 66% Training.

```{r message= FALSE, warning=FALSE}
set.seed(666)
y <- datos_final$E_CARDIACA # Variable objetivo
X <- datos_final[nombres_columnas] # Variables predictoras

split_prop <- 3
indexes = sample(1:nrow(X), size=floor(((split_prop-1)/split_prop)*nrow(X)))
train_X <- X[indexes,]
train_y <- y[indexes]
test_X <- X[-indexes,]
test_y <- y[-indexes]
```

Comprobamos que las variables train_y y test_y estén balanceadas reflejo de la variable y.

```{r message= FALSE, warning=FALSE}
print("y:")
summary(y)
print("train_y:")
summary(train_y)
print("test_y:")
summary(test_y)
```
Hacemos lo mismo con las variales train_crX y test_crX y X

```{r message= FALSE, warning=FALSE}
print("X:")
summary(X)
print("train_X:")
summary(train_X)
print("test_X:")
summary(test_X)
```
Se crea el árbol de decisión usando los datos de entrenamiento (no hay que olvidar que la variable outcome es de tipo factor):

```{r message= FALSE, warning=FALSE}
tree <- C50::C5.0(train_X, train_y, rules=TRUE )
summary(tree)
```

El modelo decision tree explica con dos reglas la probabilidad de sufrir una enfermedad cardiaca en función de las variables: TIPO DOLOR TORAX, COLESTEROL  FREC CARDÍACA MÁX,  OLDPEAK,  PENDIENTE ST:

  + Regla: 1 -> TIPO DE DOLOR DE TORAX con valores entre {1, 2} y PENDIENTE_ST <- 0 No tienen probabilidad de sufrir enfermadad cardiaca.
  + Regla: 2 -> OLDPEAK entre {-1.1 y 3} con PENDIENTE_ST <- 0 No tienen probabilidad de sufrir Enfremedad Cardiaca.
  + Regla: 3 -> TIPO_DOLOR_TORAX <- 3 y OLDPEAK entre {-1, 2.8} Tienen probabilidad de padecer enfermedad cardiaca.
  + Regla 4 -> entre {1,2} -> Tienen probabilidad de tener enfermedad cardiaca.

El modelo solo usa la variable predictora PENDIENTE ST, y tiene una tasa de error de 14.2 % es decir es capaz de explicar el 82.6 % de los casos.

De manera más gráfica:

```{r message= FALSE, warning=FALSE}
model <- C50::C5.0(train_X, train_y)
plot(model)
```

Como podemos observar de manara visual el modelo basado en arbol de decisión, solo tiene en cuenta la variable "PENDIENTE_ST", para decidir entre si un paciente es propenso a sufrir una enfermedad cardiaca o no.

### Evaluación del modelo arbol de decision

Una vez tenemos el modelo, podemos comprobar su calidad prediciendo la clase para los datos de prueba que nos hemos reservado al principio.

```{r message= FALSE, warning=FALSE}
predicted_model <- predict( tree, test_X, type="class" )
print(sprintf("La precisión del árbol es: %.4f %%",100*sum(predicted_model == test_y) / length(predicted_model)))
```

Cuando hay pocas clases, la calidad de la predicción se puede analizar mediante una matriz de confusión que identifica los tipos de errores cometidos.

```{r message= FALSE, warning=FALSE}
mat_conf <- table(test_y, Predicted=predicted_model)
mat_conf
```
De la matriz de confusión observamos los siguientes valores:

  + Verdaderos Negativos (E. CARDIACA): 85
  + Verdaderos Positivos (E. CARDIACA): 142
  + Falsos Negativos (E. CARDIACA): 32
  + Falsos Positivos (E. CARDIACA): 12

El modelo podria mejorarse sesgando a minimizar los falos negativos, ya que no queremos que se nos escapen del diagnostico pacientes que puedan desarrollar una enfermedad cardiaca.

## Random Forest

Nos interesa saber para las predicciones que variable son las que tienen más influencia. Así, probaremos con un enfoque algorítmico de Random Forest y obtendremos métricas de interpretabilidad con la librería IML (<https://cran.r-project.org/web/packages/iml/iml.pdf>). As:

```{r message= FALSE, warning=FALSE}
colnames(train_X)
train.data <- as.data.frame(cbind(train_X ,train_y))
colnames(train.data)[5] <- "E_CARDIACA"
rf <-  randomForest(E_CARDIACA ~ ., data = train.data, ntree = 50)

X <- train.data[which(names(train.data) != "E_CARDIACA")]
predictor <- Predictor$new(rf, data = X, y = train.data$E_CARDIACA) 
imp <- FeatureImp$new(predictor, loss = "ce")
plot(imp)
imp$results
```

Podemos medir y graficar la importancia de cada variable para las predicciones del random forest con *FeatureImp*. La medida se basa funciones de pérdida de rendimiento que en nuestro caso será con el objetivo de clasificación ("ce").

```{r message= FALSE, warning=FALSE}
X <- train.data[which(names(train.data) != "E_CARDIACA")]
predictor <- Predictor$new(rf, data = X, y = train.data$E_CARDIACA) 
imp <- FeatureImp$new(predictor, loss = "ce")
plot(imp)
imp$results
```

Precisión del modelo Random Forest
```{r message= FALSE, warning=FALSE}
# Extraido de la matriz de confusion
print(paste0("La precsión del modelo randomforest es: ",
             (as.numeric(rf$confusion[1,][1]) / (as.numeric(rf$confusion[1,][1]) +
                                                   as.numeric(rf$confusion[1,][2]))) * 100))
```

Podemos observar el grado de importancia de las variables:

```{r message= FALSE, warning=FALSE}
X <- train.data[which(names(train.data) != "E_CARDIACA")]
predictor_cr <- Predictor$new(rf, data = X, y = train.data$E_CARDIACA) 


effs <- FeatureEffects$new(predictor_cr)
plot(effs)
```

Parece ser que para el modelo de clasificación Random Forest la variable que toma mayor importancia es OLDPEAK.

Podemos verlo de manera textual:

```{r message= FALSE, warning=FALSE}
rf$importance
```

Otros modelos basados en arboles de decision:

```{r message= FALSE, warning=FALSE}
tree_2 <- rpart(formula = train_y ~ ., data = train_X)
tree_2
```

Visualizamos el modelo:

```{r message= FALSE, warning=FALSE}
rpart.plot(tree_2)
```

El modelo inicialmente se fija en la variable PENDIENTE_ST tanto como si es 0 como si es 1 se fija en TIPO_DOLOR_TORX (en cualquier caso se fija en los valores 1, 2 de dicha variable), después en funcion del rango de valores de OLDPEAK.

La probabilidades de sifrir enfermedad cardiaca son menores con PENDIENTE_ST=0, tanto en el caso en el que TIPO_DOLOR_TORAX esté en rango de valores de {1,2} al igual de que TIPO_DOLOR_TORAX no este en dicho rango, si se cumple que OLDPEAK esté en el rango {0-2.3}. En el otro caso habrá probabilidad alta de enfermedad cardiaca.

Para el caso de PENDIENTE_ST distinto a 0, y TIPO_DOLOR_TORAX en rango {1,2} si OLDPEAK está comprendido en rango {0-3.5} habrá pocas probabilidades de ENFERMEDAD CARDIACA, para los demás casos habrá altas probabilidades de enfermedad cardiaca.

# Conclusiones

Tras realizar con el conjunto de datos distintas pruebas estadísticas y distintos modelos, nos damos cuenta de que todas las variables son necesarias para detectar enfermedades cardiacas. No obstante, dependiendo del modelo, no todas hay que usarlas.

Con los diversos modelos, hemos explorado distintas formas de predicción, como, por ejemplo, en las pruebas del modelo de regresión logística, los resultados de las pruebas han estado muy bien para comprobar las eficacia de dicho modelo. Por otro lado, los árboles de decisión la precisión también es muy buena.

En conclusión, con este análisis de datos se contestan las preguntas planteadas inicialmente, y se da unos modelos predictivos para detectar futuros casos.

